# ğŸ¯ Comprehensive Machine Learning Experiments

A complete machine learning analysis spanning **4 major experimental domains** with production-ready models, interactive dashboard, and comprehensive documentation.

## ğŸ“Š Overview

This project demonstrates advanced ML techniques across regression and classification tasks using weather (96,453 samples) and heart disease (1,190 samples) datasets.

### ğŸ† Key Achievements

- **4 Production Models** saved with complete metadata
- **18,400+ CV Fits** across comprehensive GridSearch experiments
- **Interactive Dashboard** with real-time predictions (Streamlit)
- **39-page LaTeX Report** with detailed methodology and visualizations

## ğŸ¯ Experimental Domains

### 1ï¸âƒ£ Temperature Regression (Ensemble)
- **Best Model:** Stacking Ensemble (6 base models + Ridge meta-learner)
- **Performance:** RÂ² = 0.7889, MAE = 3.47Â°C
- **Features:** 8 weather variables
- **Innovation:** Improved from RÂ²=0.7667 (single model) to 0.7889 (ensemble)

### 2ï¸âƒ£ Heart Disease Classification
- **Best Model (AUC):** ExtraTrees - ROC-AUC = 0.9782
- **Best Model (Accuracy):** XGBoost - 93.70%
- **Features:** 11 clinical measurements
- **Innovation:** ROC-AUC prioritization for medical ML applications

### 3ï¸âƒ£ Multi-Output Regression
- **Best Model:** XGBoost MultiOutputRegressor
- **Performance:** 
  - Pressure: RÂ² = 0.9823
  - Humidity: RÂ² = 0.8741
- **Innovation:** Simultaneous prediction of 2 targets in single forward pass

### 4ï¸âƒ£ Weather Classification (4-class)
- **Best Model:** Random Forest
- **Performance:** ROC-AUC = 0.8493, Accuracy = 64.74%
- **Features:** 31 engineered features from 11 raw variables
- **Classes:** Clear, Mostly Cloudy, Overcast, Partly Cloudy

## ğŸš€ Features

### Advanced Techniques
- âœ… **Multi-Output Learning** - Single model predicting multiple targets
- âœ… **Ensemble Methods** - Voting & Stacking with meta-learners
- âœ… **Feature Engineering** - 31 engineered weather features (cyclical encoding, interactions, polynomials)
- âœ… **Comprehensive GridSearch** - 18,400+ parameter combinations tested
- âœ… **SVM Kernel Analysis** - 5 variants across 3 normalizations
- âœ… **Distribution-Preserving Imputation** - Maintaining statistical integrity

### Production Ready
- ğŸ“¦ **Saved Models** - 4 models with joblib + metadata JSON
- ğŸ¨ **Interactive Dashboard** - Streamlit app with prediction interfaces
- ğŸ“Š **35+ Visualizations** - Performance comparisons, feature importance, distributions
- ğŸ“„ **Complete Documentation** - 39-page LaTeX report + Markdown

## ğŸ› ï¸ Technology Stack

- **ML Libraries:** scikit-learn, XGBoost, LightGBM
- **Data Processing:** pandas, numpy
- **Visualization:** matplotlib, seaborn
- **Dashboard:** Streamlit
- **Documentation:** LaTeX, Markdown

## ğŸ“ Project Structure

```
ML tp0/
â”œâ”€â”€ dashboard_v2.py                    # Interactive Streamlit dashboard
â”œâ”€â”€ ml_pipeline_knn.py                 # Temperature regression pipeline
â”œâ”€â”€ ml_analysis.py                     # Heart disease classification
â”œâ”€â”€ multi_output_regression.py         # Multi-output experiments
â”œâ”€â”€ encoding_comparison.py             # Weather classification
â”œâ”€â”€ Dataset1.csv                       # Weather data (96,453 samples)
â”œâ”€â”€ Dataset2/                          # Heart disease data
â”‚   â””â”€â”€ classification_results/
â”‚       â””â”€â”€ models/                    # Saved heart disease models
â”œâ”€â”€ ensemble_results/models/           # Temperature ensemble models
â”œâ”€â”€ multi_output_results/models/       # Multi-output models
â”œâ”€â”€ weather_classification_models/     # Weather classification models
â””â”€â”€ Overleaf_Upload/
    â””â”€â”€ ML_Experiments_COMPLETE.tex    # 39-page LaTeX report
```

## ğŸ® Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Run the Dashboard

```bash
streamlit run dashboard_v2.py
```

The dashboard will open at `http://localhost:8502`

### 3. Explore Experiments

Navigate through 6 sections:
- ğŸŒ¡ï¸ Temperature Regression
- â¤ï¸ Heart Disease Classification
- ğŸ¯ Multi-Output Regression
- â˜ï¸ Weather Classification
- ğŸ¤ Ensemble Methods Comparison
- ğŸ”® Model Predictions (Interactive)

## ğŸ”® Model Predictions

The dashboard includes interactive prediction interfaces for all 4 production models:

1. **Heart Disease Risk Assessment** - 11 clinical features â†’ Risk score + confidence
2. **Temperature Prediction** - 8 weather variables â†’ Temperature Â± uncertainty
3. **Multi-Output Prediction** - Simultaneous Pressure & Humidity prediction
4. **Weather Classification** - 4-class probability distribution

## ğŸ“Š Results Summary

| Task | Best Model | Primary Metric | Score | Saved |
|------|-----------|----------------|-------|-------|
| Temperature | Stacking Ensemble | RÂ² | 0.7889 | âœ… |
| Heart Disease (AUC) | ExtraTrees | ROC-AUC | 0.9782 | âœ… |
| Heart Disease (Acc) | XGBoost | Accuracy | 93.70% | - |
| Pressure (Multi) | XGBoost Multi | RÂ² | 0.9823 | âœ… |
| Humidity (Multi) | XGBoost Multi | RÂ² | 0.8741 | âœ… |
| Weather Summary | Random Forest | ROC-AUC | 0.8493 | âœ… |

## ğŸ§ª Experimental Highlights

### Heart Disease Classification
- **47 model configurations** tested (13 models Ã— 3 normalizations + GridSearch + Ensembles)
- **ROC-AUC prioritization** for medical diagnosis (better than accuracy)
- **SVM kernel comparison:** Quantified normalization impact (+15%)
- **Production deployment:** Complete metadata for clinical integration

### Multi-Output Regression
- **1,080 CV fits** in XGBoost GridSearch alone
- **Simultaneous prediction** of correlated weather variables
- **Computational efficiency:** Single model vs separate models
- **Distribution preservation:** Handling 1,288 zero-pressure anomalies

### Weather Classification
- **31 engineered features:**
  - Cyclical temporal encoding (Month_sin, Hour_cos, etc.)
  - Interaction terms (TempÃ—Humidity, PressureÃ—Temp)
  - Polynomial features (TempÂ², WindSpeedÂ²)
  - Domain indicators (Low_Pressure, Is_Winter, Is_Day)
- **4-class imbalance handling**
- **Random Forest superiority** without normalization

## ğŸ“ˆ Key Insights

1. **Ensemble Stacking** improved temperature RÂ² by +2.2% over best single model
2. **ROC-AUC** is superior to accuracy for medical ML (98% vs 94%)
3. **Multi-output learning** enables efficient correlated prediction
4. **Feature engineering** is critical (31 features from 11 raw variables)
5. **Normalization matters** for distance-based models (+15% for SVM)

## ğŸ“š Documentation

- **LaTeX Report:** `Overleaf_Upload/ML_Experiments_COMPLETE.tex` (39 pages)
- **Compiled PDF:** Complete with visualizations and methodology
- **Dashboard:** Interactive exploration of all experiments

## ğŸ¤ Contributing

This is an academic project demonstrating comprehensive ML experimentation. Feel free to:
- Explore the code and methodology
- Adapt techniques for your own projects
- Provide feedback or suggestions

## ğŸ“„ License

Academic project - 2025/2026

## ğŸ‘¨â€ğŸ’» Author

Machine Learning Practical Work - Complete Experimental Suite

---

**â­ Features:**
- 4 Production Models | 100+ Configurations | 18,400+ CV Fits
- Interactive Dashboard | 35+ Visualizations | 39-Page Report
- Multi-Output Learning | Advanced Feature Engineering | Ensemble Methods
